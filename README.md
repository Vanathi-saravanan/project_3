Before model training, extensive data preprocessing was performed to ensure data quality and model suitability. Unstructured data was cleaned, and missing values were either imputed using statistical measures or removed if insignificant.
Outliers in key numerical features such as kmDriven and price were treated using the IQR method to prevent bias. Feature engineering included applying log transformation to skewed features (kmDriven, max_power, no_of_cylinder) for a more normalized distribution, label encoding categorical variables (fuelType, bodyType, oem).These steps ensured that the dataset was structured, balanced, and optimized for machine learning models. Several regression models were tested and evaluated to identify the best fit for predicting used car prices.
Linear Regression was chosen as a baseline to assess fundamental relationships, though it assumes a strict linear dependency. Decision Tree Regressor was considered for its ability to capture non-linearity, but it risks overfitting. Random Forest Regressor was implemented to mitigate overfitting by averaging multiple trees and providing feature importance insights. Gradient Boosting Regressor was tested for its sequential learning capability to reduce bias, while Lasso and Ridge regression models were used to prevent overfitting through regularization.
Model evaluation involved 5-fold cross-validation with metrics such as MAE, MSE, and R² score. Hyperparameter tuning using GridSearchCV was performed for Random Forest, Gradient Boosting, Decision Tree, Lasso, and Ridge models to optimize their performance. The final model selection was based on achieving the highest R² score and lowest error metrics, ensuring an accurate and reliable price prediction system.Thus Gradient Boosting Regressor was chosen as best model.
